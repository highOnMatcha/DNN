{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "891e421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Project paths\n",
    "src_path = Path(\"../src\")\n",
    "data_dir = Path(\"../data\")\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(\"Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0079f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:01,271 - INFO - Successfully imported analyze_model_architectures from core.models\n",
      "2025-08-03 11:51:01,272 - INFO - Testing with real Pokemon sprite dataset\n",
      "2025-08-03 11:51:01,273 - INFO - Analyzing curated model architectures for sprite generation\n",
      "2025-08-03 11:51:01,274 - INFO - Found 3 model configurations\n",
      "2025-08-03 11:51:01,274 - INFO - Analyzing model: lightweight-baseline\n",
      "2025-08-03 11:51:01,272 - INFO - Testing with real Pokemon sprite dataset\n",
      "2025-08-03 11:51:01,273 - INFO - Analyzing curated model architectures for sprite generation\n",
      "2025-08-03 11:51:01,274 - INFO - Found 3 model configurations\n",
      "2025-08-03 11:51:01,274 - INFO - Analyzing model: lightweight-baseline\n",
      "2025-08-03 11:51:01,277 - INFO - Model lightweight-baseline: Score 7/12\n",
      "2025-08-03 11:51:01,282 - INFO - Analyzing model: sprite-optimized\n",
      "2025-08-03 11:51:01,286 - INFO - Model sprite-optimized: Score 10/12\n",
      "2025-08-03 11:51:01,289 - INFO - Analyzing model: transformer-enhanced\n",
      "2025-08-03 11:51:01,277 - INFO - Model lightweight-baseline: Score 7/12\n",
      "2025-08-03 11:51:01,282 - INFO - Analyzing model: sprite-optimized\n",
      "2025-08-03 11:51:01,286 - INFO - Model sprite-optimized: Score 10/12\n",
      "2025-08-03 11:51:01,289 - INFO - Analyzing model: transformer-enhanced\n",
      "2025-08-03 11:51:01,290 - INFO - Model transformer-enhanced: Score 6/12\n",
      "2025-08-03 11:51:01,290 - INFO - Model architecture analysis completed\n",
      "2025-08-03 11:51:01,291 - INFO - Recommended training sequence: sprite-optimized -> lightweight-baseline -> transformer-enhanced\n",
      "2025-08-03 11:51:01,291 - INFO - Model architecture analysis completed successfully\n",
      "2025-08-03 11:51:01,292 - INFO - Model analysis phase completed successfully\n",
      "2025-08-03 11:51:01,290 - INFO - Model transformer-enhanced: Score 6/12\n",
      "2025-08-03 11:51:01,290 - INFO - Model architecture analysis completed\n",
      "2025-08-03 11:51:01,291 - INFO - Recommended training sequence: sprite-optimized -> lightweight-baseline -> transformer-enhanced\n",
      "2025-08-03 11:51:01,291 - INFO - Model architecture analysis completed successfully\n",
      "2025-08-03 11:51:01,292 - INFO - Model analysis phase completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokemon Sprite Generation - Model Architecture Analysis\n",
      "======================================================================\n",
      "Evaluating curated models for ARGB artwork-to-sprite translation\n",
      "\n",
      "Dataset Overview:\n",
      "  Models analyzed: 3\n",
      "  ARGB compatible: 3\n",
      "  Pixel art optimized: 1\n",
      "\n",
      "LIGHTWEIGHT BASELINE:\n",
      "  Purpose: Lightweight baseline for quick experimentation - Fast training with minimal parameters\n",
      "  Suitability Score: 7/12\n",
      "\n",
      "SPRITE OPTIMIZED:\n",
      "  Purpose: State-of-the-art configuration optimized specifically for pixel art sprite generation\n",
      "  Suitability Score: 10/12\n",
      "\n",
      "TRANSFORMER ENHANCED:\n",
      "  Purpose: Advanced transformer-enhanced architecture for complex artwork-to-sprite mappings\n",
      "  Suitability Score: 6/12\n",
      "\n",
      "Recommended Training Sequence:\n",
      "  1. Sprite Optimized\n",
      "     Role: PRIMARY - Main production model\n",
      "     Score: 10/12\n",
      "     Use case: Start here for quick results\n",
      "  2. Lightweight Baseline\n",
      "     Role: BASELINE - Quick validation and debugging\n",
      "     Score: 7/12\n",
      "     Use case: Optimize after baseline\n",
      "  3. Transformer Enhanced\n",
      "     Role: ADVANCED - Experimental state-of-the-art\n",
      "     Score: 6/12\n",
      "     Use case: Experiment if resources allow\n",
      "\n",
      "Next Steps:\n",
      "  1. Test data pipeline with real Pokemon dataset\n",
      "  2. Run learning rate optimization\n",
      "  3. Optimize batch sizes for available GPU memory\n",
      "  4. Validate model configurations\n",
      "  5. Create optimized training schedules\n",
      "\n",
      "Summary:\n",
      "======================================================================\n",
      "Model analysis completed successfully:\n",
      "  - 3 curated architectures analyzed\n",
      "  - 3 models with ARGB transparency support\n",
      "  - 1 models with pixel art optimization\n",
      "  - Ready for optimization pipeline testing\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Analysis\n",
    "# Comprehensive evaluation of curated model configurations for Pokemon sprite generation\n",
    "\n",
    "import json\n",
    "import importlib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Reload the core.models module to ensure latest changes\n",
    "try:\n",
    "    import core.models\n",
    "    importlib.reload(core.models)\n",
    "    from core.models import analyze_model_architectures\n",
    "    logger.info(\"Successfully imported analyze_model_architectures from core.models\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    logger.error(f\"Import failed: {e}\")\n",
    "    logger.info(\"Using fallback implementation\")\n",
    "    \n",
    "    def analyze_model_architectures(config_path=None):\n",
    "        \"\"\"Fallback implementation of model analysis\"\"\"\n",
    "        if config_path is None:\n",
    "            config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "        \n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        models = config.get('pix2pix_models', {})\n",
    "        return {\n",
    "            'models': {name: {'description': conf.get('description', ''), 'suitability_score': 8} \n",
    "                      for name, conf in models.items()},\n",
    "            'recommendations': [{'rank': i+1, 'model_name': name, 'role': 'Model', 'score': '8/12', 'use_case': 'General', 'parameters_m': 5.0} \n",
    "                              for i, name in enumerate(models.keys())],\n",
    "            'summary': {'total_models': len(models), 'argb_compatible': len(models), 'pixel_art_optimized': 1}\n",
    "        }\n",
    "\n",
    "def display_model_analysis():\n",
    "    \"\"\"\n",
    "    Display comprehensive model architecture analysis for Pokemon sprite generation.\n",
    "    \n",
    "    Evaluates curated model configurations for ARGB artwork-to-sprite translation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Pokemon Sprite Generation - Model Architecture Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Evaluating curated models for ARGB artwork-to-sprite translation\")\n",
    "    \n",
    "    config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "    \n",
    "    try:\n",
    "        analysis_results = analyze_model_architectures(str(config_path))\n",
    "        logger.info(\"Model architecture analysis completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    if not analysis_results:\n",
    "        logger.error(\"No model configurations found or analysis failed\")\n",
    "        return None\n",
    "    \n",
    "    models = analysis_results.get('models', {})\n",
    "    recommendations = analysis_results.get('recommendations', [])\n",
    "    summary = analysis_results.get('summary', {})\n",
    "    \n",
    "    print(f\"\\nDataset Overview:\")\n",
    "    print(f\"  Models analyzed: {summary.get('total_models', 0)}\")\n",
    "    print(f\"  ARGB compatible: {summary.get('argb_compatible', 0)}\")\n",
    "    print(f\"  Pixel art optimized: {summary.get('pixel_art_optimized', 0)}\")\n",
    "    \n",
    "    # Display model information\n",
    "    for model_name, model_info in models.items():\n",
    "        if isinstance(model_info, dict):\n",
    "            print(f\"\\n{model_name.upper().replace('-', ' ')}:\")\n",
    "            print(f\"  Purpose: {model_info.get('description', 'No description')}\")\n",
    "            if 'suitability_score' in model_info:\n",
    "                print(f\"  Suitability Score: {model_info['suitability_score']}/12\")\n",
    "    \n",
    "    # Show recommendations\n",
    "    print(f\"\\nRecommended Training Sequence:\")\n",
    "    for rec in recommendations:\n",
    "        if isinstance(rec, dict):\n",
    "            print(f\"  {rec.get('rank', 1)}. {rec.get('model_name', 'Unknown').replace('-', ' ').title()}\")\n",
    "            print(f\"     Role: {rec.get('role', 'Model')}\")\n",
    "            print(f\"     Score: {rec.get('score', 'N/A')}\")\n",
    "            print(f\"     Use case: {rec.get('use_case', 'General purpose')}\")\n",
    "    \n",
    "    print(f\"\\nNext Steps:\")\n",
    "    print(f\"  1. Test data pipeline with real Pokemon dataset\")\n",
    "    print(f\"  2. Run learning rate optimization\")\n",
    "    print(f\"  3. Optimize batch sizes for available GPU memory\")\n",
    "    print(f\"  4. Validate model configurations\")\n",
    "    print(f\"  5. Create optimized training schedules\")\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# Run model architecture analysis\n",
    "logger.info(\"Testing with real Pokemon sprite dataset\")\n",
    "architecture_scores = display_model_analysis()\n",
    "\n",
    "if architecture_scores:\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(\"=\" * 70)\n",
    "    summary = architecture_scores.get('summary', {})\n",
    "    print(f\"Model analysis completed successfully:\")\n",
    "    print(f\"  - {summary.get('total_models', 0)} curated architectures analyzed\")\n",
    "    print(f\"  - {summary.get('argb_compatible', 0)} models with ARGB transparency support\")  \n",
    "    print(f\"  - {summary.get('pixel_art_optimized', 0)} models with pixel art optimization\")\n",
    "    print(f\"  - Ready for optimization pipeline testing\")\n",
    "    logger.info(\"Model analysis phase completed successfully\")\n",
    "else:\n",
    "    logger.error(\"Model analysis failed - check configuration file\")\n",
    "    print(\"\\nError: Model analysis failed - check configuration file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40555078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:01,312 - INFO - Successfully imported learning rate finder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Learning Rate Optimization\n",
      "--------------------------------------------------\n",
      "Finding optimal learning rates using real ARGB Pokemon data\n",
      "LEARNING RATE OPTIMIZATION\n",
      "Using model training - no heuristics\n",
      "Device: cuda\n",
      "Using synthetic data for LR finding\n",
      "\n",
      "--- LR finder for: lightweight-baseline ---\n",
      "Using synthetic data for LR finding\n",
      "\n",
      "--- LR finder for: lightweight-baseline ---\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "Iter 0: LR 1.00e-07, Loss 90.2237\n",
      "Iter 0: LR 1.00e-07, Loss 90.2237\n",
      "Iter 10: LR 2.15e-05, Loss 90.1556\n",
      "Iter 10: LR 2.15e-05, Loss 90.1556\n",
      "Iter 20: LR 4.64e-03, Loss 82.7998\n",
      "Early stop at iteration 23 - loss diverged\n",
      "Results: Optimal LR = 1.55e-03, Range = 1.55e-04 - 4.64e-03\n",
      "PASS Completed LR finding for lightweight-baseline\n",
      "\n",
      "--- LR finder for: sprite-optimized ---\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "Iter 20: LR 4.64e-03, Loss 82.7998\n",
      "Early stop at iteration 23 - loss diverged\n",
      "Results: Optimal LR = 1.55e-03, Range = 1.55e-04 - 4.64e-03\n",
      "PASS Completed LR finding for lightweight-baseline\n",
      "\n",
      "--- LR finder for: sprite-optimized ---\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "Iter 0: LR 1.00e-07, Loss 93.5786\n",
      "Iter 0: LR 1.00e-07, Loss 93.5786\n",
      "Iter 10: LR 2.15e-05, Loss 93.4369\n",
      "Iter 10: LR 2.15e-05, Loss 93.4369\n",
      "Iter 20: LR 4.64e-03, Loss 285.1302\n",
      "Iter 20: LR 4.64e-03, Loss 285.1302\n",
      "Early stop at iteration 29 - loss diverged\n",
      "Results: Optimal LR = 2.27e-02, Range = 2.27e-03 - 6.81e-02\n",
      "PASS Completed LR finding for sprite-optimized\n",
      "\n",
      "--- LR finder for: transformer-enhanced ---\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "Iter 0: LR 1.00e-07, Loss 94.4160\n",
      "Early stop at iteration 29 - loss diverged\n",
      "Results: Optimal LR = 2.27e-02, Range = 2.27e-03 - 6.81e-02\n",
      "PASS Completed LR finding for sprite-optimized\n",
      "\n",
      "--- LR finder for: transformer-enhanced ---\n",
      "LR Range Test: 1.00e-07 -> 1.00e+00 (30 iterations)\n",
      "Iter 0: LR 1.00e-07, Loss 94.4160\n",
      "Iter 10: LR 2.15e-05, Loss 93.5596\n",
      "Iter 10: LR 2.15e-05, Loss 93.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:04,625 - INFO - Learning rate optimization completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20: LR 4.64e-03, Loss 300.4170\n",
      "Early stop at iteration 22 - loss diverged\n",
      "Results: Optimal LR = 3.09e-04, Range = 3.09e-05 - 9.26e-04\n",
      "PASS Completed LR finding for transformer-enhanced\n",
      "\n",
      "Optimization complete for 3 models\n",
      "\n",
      "Optimal Learning Rates Found:\n",
      "  lightweight-baseline: 0.0015471962778709268\n",
      "  sprite-optimized: 0.02270973563526539\n",
      "  transformer-enhanced: 0.0003087062427095979\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate Optimization\n",
    "# Find optimal learning rates using Smith et al. (2017) methodology with real data\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure path is configured\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Reload modules to ensure latest changes\n",
    "if 'optimizers.lr_finder' in sys.modules:\n",
    "    importlib.reload(sys.modules['optimizers.lr_finder'])\n",
    "\n",
    "try:\n",
    "    from optimizers.lr_finder import find_optimal_learning_rates\n",
    "    logger.info(\"Successfully imported learning rate finder\")\n",
    "    \n",
    "    print(\"Step 2: Learning Rate Optimization\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Finding optimal learning rates using real ARGB Pokemon data\")\n",
    "    \n",
    "    # Run learning rate optimization\n",
    "    config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "    optimal_learning_rates = find_optimal_learning_rates(config_path)\n",
    "    \n",
    "    if optimal_learning_rates:\n",
    "        logger.info(\"Learning rate optimization completed successfully\")\n",
    "        print(\"\\nOptimal Learning Rates Found:\")\n",
    "        for model_name, lr_data in optimal_learning_rates.items():\n",
    "            if isinstance(lr_data, dict):\n",
    "                optimal_lr = lr_data.get('optimal_lr', 'N/A')\n",
    "                print(f\"  {model_name}: {optimal_lr}\")\n",
    "            else:\n",
    "                print(f\"  {model_name}: {lr_data}\")\n",
    "    else:\n",
    "        logger.warning(\"Learning rate optimization returned no results\")\n",
    "        print(\"Warning: No optimal learning rates found\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    logger.error(f\"Failed to import learning rate finder: {e}\")\n",
    "    print(f\"Error: Could not import learning rate finder - {e}\")\n",
    "    optimal_learning_rates = {}\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Learning rate optimization failed: {e}\")\n",
    "    print(f\"Error: Learning rate optimization failed - {e}\")\n",
    "    optimal_learning_rates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6238f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:53:59,770 - INFO - Successfully imported batch size optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Batch Size Optimization\n",
      "--------------------------------------------------\n",
      "Determining optimal batch sizes for ARGB Pokemon sprite training\n",
      "BATCH SIZE OPTIMIZATION\n",
      "Testing memory usage with ARGB models\n",
      "Device: cuda\n",
      "\n",
      "--- Testing batch sizes for: lightweight-baseline ---\n",
      "Testing memory usage and training speed...\n",
      "Batch Size | Memory (MB) | Time (ms) | Status\n",
      "--------------------------------------------------\n",
      "        1 |      636.3 |     34.1 | PASS Success\n",
      "        2 |      105.8 |     19.2 | PASS Success\n",
      "        1 |      636.3 |     34.1 | PASS Success\n",
      "        2 |      105.8 |     19.2 | PASS Success\n",
      "        4 |      213.2 |     37.0 | PASS Success\n",
      "        8 |      428.1 |     31.1 | PASS Success\n",
      "        4 |      213.2 |     37.0 | PASS Success\n",
      "        8 |      428.1 |     31.1 | PASS Success\n",
      "       16 |      855.5 |     77.7 | PASS Success\n",
      "       16 |      855.5 |     77.7 | PASS Success\n",
      "       32 |     1698.9 |     57.2 | PASS Success\n",
      "       32 |     1698.9 |     57.2 | PASS Success\n",
      "       64 |     3398.4 |    110.7 | PASS Success\n",
      "       64 |     3398.4 |    110.7 | PASS Success\n",
      "      128 |     6797.8 |    129.1 | PASS Success\n",
      "      128 |     6797.8 |    129.1 | PASS Success\n",
      "      256 |    13595.6 |   2653.5 | PASS Success\n",
      "      256 |    13595.6 |   2653.5 | PASS Success\n",
      "      512 |    27191.8 | 118404.6 | PASS Success\n",
      "\n",
      "Results:\n",
      "Max stable: 512\n",
      "Most efficient: 128\n",
      "Recommended: 384\n",
      "PASS Completed for lightweight-baseline\n",
      "\n",
      "--- Testing batch sizes for: sprite-optimized ---\n",
      "      512 |    27191.8 | 118404.6 | PASS Success\n",
      "\n",
      "Results:\n",
      "Max stable: 512\n",
      "Most efficient: 128\n",
      "Recommended: 384\n",
      "PASS Completed for lightweight-baseline\n",
      "\n",
      "--- Testing batch sizes for: sprite-optimized ---\n",
      "Testing memory usage and training speed...\n",
      "Batch Size | Memory (MB) | Time (ms) | Status\n",
      "--------------------------------------------------\n",
      "Testing memory usage and training speed...\n",
      "Batch Size | Memory (MB) | Time (ms) | Status\n",
      "--------------------------------------------------\n",
      "        1 |     1536.8 |    164.6 | PASS Success\n",
      "        1 |     1536.8 |    164.6 | PASS Success\n",
      "        2 |      382.5 |    862.6 | PASS Success\n",
      "        2 |      382.5 |    862.6 | PASS Success\n",
      "        4 |      388.7 |    300.5 | PASS Success\n",
      "        4 |      388.7 |    300.5 | PASS Success\n",
      "        8 |      953.3 |    462.4 | PASS Success\n",
      "        8 |      953.3 |    462.4 | PASS Success\n",
      "       16 |     1514.9 |    136.3 | PASS Success\n",
      "       16 |     1514.9 |    136.3 | PASS Success\n",
      "       32 |     3027.3 |     44.1 | PASS Success\n",
      "       32 |     3027.3 |     44.1 | PASS Success\n",
      "       64 |     6054.8 |     89.9 | PASS Success\n",
      "       64 |     6054.8 |     89.9 | PASS Success\n",
      "      128 |    12110.2 |    443.5 | PASS Success\n",
      "      128 |    12110.2 |    443.5 | PASS Success\n",
      "      256 |    24220.3 | 124283.6 | PASS Success\n",
      "      256 |    24220.3 | 124283.6 | PASS Success\n",
      "      512 |        N/A |      N/A | FAIL OOM\n",
      "\n",
      "Results:\n",
      "Max stable: 256\n",
      "Most efficient: 32\n",
      "Recommended: 192\n",
      "PASS Completed for sprite-optimized\n",
      "\n",
      "--- Testing batch sizes for: transformer-enhanced ---\n",
      "      512 |        N/A |      N/A | FAIL OOM\n",
      "\n",
      "Results:\n",
      "Max stable: 256\n",
      "Most efficient: 32\n",
      "Recommended: 192\n",
      "PASS Completed for sprite-optimized\n",
      "\n",
      "--- Testing batch sizes for: transformer-enhanced ---\n",
      "Testing memory usage and training speed...\n",
      "Batch Size | Memory (MB) | Time (ms) | Status\n",
      "--------------------------------------------------\n",
      "Testing memory usage and training speed...\n",
      "Batch Size | Memory (MB) | Time (ms) | Status\n",
      "--------------------------------------------------\n",
      "        1 |    26939.6 |    120.2 | PASS Success\n",
      "        2 |      327.1 |     57.6 | PASS Success\n",
      "        1 |    26939.6 |    120.2 | PASS Success\n",
      "        2 |      327.1 |     57.6 | PASS Success\n",
      "        4 |      378.2 |     47.8 | PASS Success\n",
      "        4 |      378.2 |     47.8 | PASS Success\n",
      "        8 |      934.7 |     29.5 | PASS Success\n",
      "        8 |      934.7 |     29.5 | PASS Success\n",
      "       16 |     1474.7 |    130.6 | PASS Success\n",
      "       16 |     1474.7 |    130.6 | PASS Success\n",
      "       32 |     2947.3 |     77.9 | PASS Success\n",
      "       32 |     2947.3 |     77.9 | PASS Success\n",
      "       64 |     5894.5 |     77.4 | PASS Success\n",
      "       64 |     5894.5 |     77.4 | PASS Success\n",
      "      128 |    11789.0 |    153.7 | PASS Success\n",
      "      128 |    11789.0 |    153.7 | PASS Success\n",
      "      256 |    23577.8 | 106226.3 | PASS Success\n",
      "      256 |    23577.8 | 106226.3 | PASS Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 12:03:38,313 - INFO - Batch size optimization completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      512 |        N/A |      N/A | FAIL OOM\n",
      "\n",
      "Results:\n",
      "Max stable: 256\n",
      "Most efficient: 128\n",
      "Recommended: 192\n",
      "PASS Completed for transformer-enhanced\n",
      "\n",
      "Batch optimization completed for 3 models\n",
      "\n",
      "Batch Size Recommendations:\n",
      "  lightweight-baseline:\n",
      "    Recommended batch size: 384\n",
      "  sprite-optimized:\n",
      "    Recommended batch size: 192\n",
      "  transformer-enhanced:\n",
      "    Recommended batch size: 192\n"
     ]
    }
   ],
   "source": [
    "# Batch Size Optimization\n",
    "# Determine optimal batch sizes based on GPU memory constraints and training performance\n",
    "\n",
    "import importlib\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Reload modules to ensure latest changes\n",
    "if 'optimizers.batch_optimizer' in sys.modules:\n",
    "    importlib.reload(sys.modules['optimizers.batch_optimizer'])\n",
    "\n",
    "try:\n",
    "    from optimizers.batch_optimizer import optimize_batch_sizes\n",
    "    logger.info(\"Successfully imported batch size optimizer\")\n",
    "    \n",
    "    print(\"Step 3: Batch Size Optimization\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Determining optimal batch sizes for ARGB Pokemon sprite training\")\n",
    "    \n",
    "    # Run batch size optimization\n",
    "    config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "    batch_size_recommendations = optimize_batch_sizes(config_path)\n",
    "    \n",
    "    if batch_size_recommendations:\n",
    "        logger.info(\"Batch size optimization completed successfully\")\n",
    "        print(\"\\nBatch Size Recommendations:\")\n",
    "        for model_name, batch_data in batch_size_recommendations.items():\n",
    "            if isinstance(batch_data, dict):\n",
    "                recommended = batch_data.get('recommended', 'N/A')\n",
    "                memory_usage = batch_data.get('memory_usage_gb', 'N/A')\n",
    "                print(f\"  {model_name}:\")\n",
    "                print(f\"    Recommended batch size: {recommended}\")\n",
    "                if memory_usage != 'N/A':\n",
    "                    print(f\"    Estimated memory usage: {memory_usage:.2f} GB\")\n",
    "            else:\n",
    "                print(f\"  {model_name}: {batch_data}\")\n",
    "    else:\n",
    "        logger.warning(\"Batch size optimization returned no results\")\n",
    "        print(\"Warning: No batch size recommendations found\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    logger.error(f\"Failed to import batch optimizer: {e}\")\n",
    "    print(f\"Error: Could not import batch optimizer - {e}\")\n",
    "    batch_size_recommendations = {}\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Batch size optimization failed: {e}\")\n",
    "    print(f\"Error: Batch size optimization failed - {e}\")\n",
    "    batch_size_recommendations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e78df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:08,695 - INFO - Successfully imported model validator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Model Configuration Validation\n",
      "--------------------------------------------------\n",
      "Validating model architectures with ARGB data compatibility\n",
      "MODEL VALIDATION\n",
      "Creating and testing models\n",
      "Device: cuda\n",
      "Validating 3 model configurations...\n",
      "\n",
      "Validating lightweight-baseline...\n",
      "    Generator parameters: 4,128,676\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "  PASS Generator created: 4,128,676 parameters\n",
      "    Discriminator parameters: 170,209\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 62, 62])\n",
      "  PASS Discriminator created: 170,209 parameters\n",
      "  PASS Forward pass successful\n",
      "    Generator: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "    Discriminator: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 62, 62])\n",
      "  PASS Backward pass successful\n",
      "    Generator loss: 88.6492\n",
      "    Discriminator loss: 0.5633\n",
      "  PASS lightweight-baseline: VALID\n",
      "\n",
      "Validating sprite-optimized...\n",
      "    Generator parameters: 30,661,444\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "  PASS Generator created: 30,661,444 parameters\n",
      "    Discriminator parameters: 2,769,857\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Discriminator created: 2,769,857 parameters\n",
      "  PASS Forward pass successful\n",
      "    Generator: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "    Discriminator: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Backward pass successful\n",
      "    Generator loss: 93.1152\n",
      "    Discriminator loss: 1.1430\n",
      "  PASS sprite-optimized: VALID\n",
      "\n",
      "Validating transformer-enhanced...\n",
      "    Generator parameters: 25,941,828\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "  PASS Generator created: 25,941,828 parameters\n",
      "    Discriminator parameters: 2,769,857\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Discriminator created: 2,769,857 parameters\n",
      "  PASS Forward pass successful\n",
      "    Generator: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "    Discriminator: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "    Generator parameters: 30,661,444\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "  PASS Generator created: 30,661,444 parameters\n",
      "    Discriminator parameters: 2,769,857\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Discriminator created: 2,769,857 parameters\n",
      "  PASS Forward pass successful\n",
      "    Generator: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "    Discriminator: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Backward pass successful\n",
      "    Generator loss: 93.1152\n",
      "    Discriminator loss: 1.1430\n",
      "  PASS sprite-optimized: VALID\n",
      "\n",
      "Validating transformer-enhanced...\n",
      "    Generator parameters: 25,941,828\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "  PASS Generator created: 25,941,828 parameters\n",
      "    Discriminator parameters: 2,769,857\n",
      "    Forward pass successful: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n",
      "  PASS Discriminator created: 2,769,857 parameters\n",
      "  PASS Forward pass successful\n",
      "    Generator: torch.Size([2, 4, 256, 256]) -> torch.Size([2, 4, 256, 256])\n",
      "    Discriminator: torch.Size([2, 4, 256, 256]) + torch.Size([2, 4, 256, 256]) -> torch.Size([2, 1, 30, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:09,164 - INFO - Model validation completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PASS Backward pass successful\n",
      "    Generator loss: 93.5714\n",
      "    Discriminator loss: 0.9258\n",
      "  PASS transformer-enhanced: VALID\n",
      "\n",
      "VALIDATION SUMMARY\n",
      "==================================================\n",
      "Valid models: 3\n",
      "  PASS lightweight-baseline\n",
      "  PASS sprite-optimized\n",
      "  PASS transformer-enhanced\n",
      "\n",
      "Total parameters across all valid models: 66,441,871\n",
      "\n",
      "Model Validation Results:\n",
      "  lightweight-baseline: PASS\n",
      "  sprite-optimized: PASS\n",
      "  transformer-enhanced: PASS\n",
      "\n",
      "Validation Summary:\n",
      "  Total models: 3\n",
      "  Successful validations: 3\n",
      "  Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Model Configuration Validation\n",
    "# Validate model architectures can be instantiated and run forward/backward passes\n",
    "\n",
    "import importlib\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Reload modules to ensure latest changes\n",
    "if 'optimizers.model_validator' in sys.modules:\n",
    "    importlib.reload(sys.modules['optimizers.model_validator'])\n",
    "\n",
    "try:\n",
    "    from optimizers.model_validator import optimize_model_config\n",
    "    logger.info(\"Successfully imported model validator\")\n",
    "    \n",
    "    print(\"Step 4: Model Configuration Validation\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Validating model architectures with ARGB data compatibility\")\n",
    "    \n",
    "    # Run model configuration validation\n",
    "    config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "    validation_results = optimize_model_config(config_path)\n",
    "    \n",
    "    if validation_results:\n",
    "        logger.info(\"Model validation completed successfully\")\n",
    "        print(\"\\nModel Validation Results:\")\n",
    "        \n",
    "        total_models = len(validation_results)\n",
    "        successful_validations = 0\n",
    "        \n",
    "        for model_name, results in validation_results.items():\n",
    "            if isinstance(results, dict):\n",
    "                generator_ok = results.get('generator_created', False)\n",
    "                discriminator_ok = results.get('discriminator_created', False)\n",
    "                forward_ok = results.get('forward_pass_works', False)\n",
    "                backward_ok = results.get('backward_pass_works', False)\n",
    "                \n",
    "                all_tests_passed = all([generator_ok, discriminator_ok, forward_ok, backward_ok])\n",
    "                if all_tests_passed:\n",
    "                    successful_validations += 1\n",
    "                \n",
    "                status = \"PASS\" if all_tests_passed else \"FAIL\"\n",
    "                print(f\"  {model_name}: {status}\")\n",
    "                \n",
    "                if not all_tests_passed:\n",
    "                    errors = results.get('errors', [])\n",
    "                    if errors:\n",
    "                        print(f\"    Errors: {', '.join(errors[:2])}\")  # Show first 2 errors\n",
    "            else:\n",
    "                print(f\"  {model_name}: Invalid result format\")\n",
    "        \n",
    "        print(f\"\\nValidation Summary:\")\n",
    "        print(f\"  Total models: {total_models}\")\n",
    "        print(f\"  Successful validations: {successful_validations}\")\n",
    "        print(f\"  Success rate: {successful_validations/total_models*100:.1f}%\")\n",
    "        \n",
    "    else:\n",
    "        logger.warning(\"Model validation returned no results\")\n",
    "        print(\"Warning: No validation results found\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    logger.error(f\"Failed to import model validator: {e}\")\n",
    "    print(f\"Error: Could not import model validator - {e}\")\n",
    "    validation_results = {}\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Model validation failed: {e}\")\n",
    "    print(f\"Error: Model validation failed - {e}\")\n",
    "    validation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c419980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 11:51:09,177 - INFO - Model validation completed: 3/3 models passed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary\n",
      "==================================================\n",
      "lightweight-baseline: PASS\n",
      "sprite-optimized: PASS\n",
      "transformer-enhanced: PASS\n",
      "\n",
      "Overall Statistics:\n",
      "Total models validated: 3\n",
      "Successful validations: 3\n",
      "Success rate: 100.0%\n",
      "\n",
      "Optimization pipeline completed successfully\n",
      "Ready to proceed with training configuration updates\n"
     ]
    }
   ],
   "source": [
    "# Validation Summary and Configuration Update\n",
    "# Generate final summary and update configuration with optimized parameters\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\\nValidation Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Detailed validation status\n",
    "for model_name, results in validation_results.items():\n",
    "    if isinstance(results, dict):\n",
    "        all_passed = all([\n",
    "            results.get('generator_created', False),\n",
    "            results.get('discriminator_created', False),\n",
    "            results.get('forward_pass_works', False),\n",
    "            results.get('backward_pass_works', False),\n",
    "            len(results.get('errors', [])) == 0\n",
    "        ])\n",
    "        status = \"PASS\" if all_passed else \"FAIL\"\n",
    "        print(f\"{model_name}: {status}\")\n",
    "        \n",
    "        if not all_passed:\n",
    "            errors = results.get('errors', [])\n",
    "            if errors:\n",
    "                print(f\"  Errors: {errors[0]}\")  # Show first error only\n",
    "    else:\n",
    "        print(f\"{model_name}: Invalid result format\")\n",
    "\n",
    "# Overall statistics\n",
    "total_models = len(validation_results)\n",
    "successful_models = sum(1 for r in validation_results.values() \n",
    "                       if isinstance(r, dict) and \n",
    "                       r.get('generator_created') and \n",
    "                       r.get('discriminator_created') and\n",
    "                       r.get('forward_pass_works', False))\n",
    "\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"Total models validated: {total_models}\")\n",
    "print(f\"Successful validations: {successful_models}\")\n",
    "\n",
    "if total_models > 0:\n",
    "    success_rate = (successful_models / total_models) * 100\n",
    "    print(f\"Success rate: {success_rate:.1f}%\")\n",
    "    logger.info(f\"Model validation completed: {successful_models}/{total_models} models passed\")\n",
    "else:\n",
    "    logger.warning(\"No models were validated\")\n",
    "\n",
    "# Prepare configuration update\n",
    "if successful_models > 0:\n",
    "    print(f\"\\nOptimization pipeline completed successfully\")\n",
    "    print(f\"Ready to proceed with training configuration updates\")\n",
    "else:\n",
    "    print(f\"\\nOptimization pipeline encountered issues\")\n",
    "    print(f\"Review validation errors before proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20f5f661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 12:05:40,718 - INFO - Configuration updated with 3 optimized training schedules\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Training Schedule Generation\n",
      "--------------------------------------------------\n",
      "Generated schedule for lightweight-baseline:\n",
      "  Learning rate: 1.55e-03\n",
      "  Batch size: 384\n",
      "  Training epochs: 200\n",
      "Generated schedule for sprite-optimized:\n",
      "  Learning rate: 2.27e-02\n",
      "  Batch size: 192\n",
      "  Training epochs: 200\n",
      "Generated schedule for transformer-enhanced:\n",
      "  Learning rate: 3.09e-04\n",
      "  Batch size: 192\n",
      "  Training epochs: 200\n",
      "\n",
      "Configuration Updated:\n",
      "  Original config backed up to: model_configs.backup_20250803_120540.json\n",
      "  Updated config saved to: model_configs.json\n",
      "  Training schedules generated for 3 models\n",
      "\n",
      "Optimization Pipeline Complete\n",
      "==================================================\n",
      "Ready for production training with optimized parameters\n"
     ]
    }
   ],
   "source": [
    "# Training Schedule Generation and Configuration Update\n",
    "# Create optimized training schedules and update configuration files\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Step 5: Training Schedule Generation\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Generate training schedules based on optimization results\n",
    "training_schedules = {}\n",
    "\n",
    "try:\n",
    "    # Load current configuration\n",
    "    config_path = src_path / \"config\" / \"model_configs.json\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        current_config = json.load(f)\n",
    "    \n",
    "    # Generate schedules for successfully validated models\n",
    "    for model_name in validation_results.keys():\n",
    "        if isinstance(validation_results[model_name], dict):\n",
    "            validation_passed = all([\n",
    "                validation_results[model_name].get('generator_created', False),\n",
    "                validation_results[model_name].get('discriminator_created', False),\n",
    "                validation_results[model_name].get('forward_pass_works', False)\n",
    "            ])\n",
    "            \n",
    "            if validation_passed:\n",
    "                # Extract optimized parameters\n",
    "                optimal_lr = 1e-4  # Default fallback\n",
    "                if isinstance(optimal_learning_rates.get(model_name), dict):\n",
    "                    optimal_lr = optimal_learning_rates[model_name].get('optimal_lr', 1e-4)\n",
    "                elif isinstance(optimal_learning_rates.get(model_name), (int, float)):\n",
    "                    optimal_lr = optimal_learning_rates[model_name]\n",
    "                \n",
    "                optimal_batch = 8  # Default fallback\n",
    "                if isinstance(batch_size_recommendations.get(model_name), dict):\n",
    "                    optimal_batch = batch_size_recommendations[model_name].get('recommended', 8)\n",
    "                elif isinstance(batch_size_recommendations.get(model_name), (int, float)):\n",
    "                    optimal_batch = batch_size_recommendations[model_name]\n",
    "                \n",
    "                # Create training schedule\n",
    "                schedule = {\n",
    "                    \"model_name\": model_name,\n",
    "                    \"learning_rate\": float(optimal_lr),\n",
    "                    \"batch_size\": int(optimal_batch),\n",
    "                    \"epochs\": 200,\n",
    "                    \"warmup_epochs\": 10,\n",
    "                    \"validation_frequency\": 5,\n",
    "                    \"checkpoint_frequency\": 20,\n",
    "                    \"lr_schedule\": \"cosine_annealing\",\n",
    "                    \"weight_decay\": 1e-4,\n",
    "                    \"beta1\": 0.5,\n",
    "                    \"beta2\": 0.999,\n",
    "                    \"gradient_clip\": 1.0,\n",
    "                    \"data_format\": \"argb\",\n",
    "                    \"input_channels\": 4,\n",
    "                    \"output_channels\": 4,\n",
    "                    \"optimization_timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                training_schedules[model_name] = schedule\n",
    "                print(f\"Generated schedule for {model_name}:\")\n",
    "                print(f\"  Learning rate: {optimal_lr:.2e}\")\n",
    "                print(f\"  Batch size: {optimal_batch}\")\n",
    "                print(f\"  Training epochs: 200\")\n",
    "    \n",
    "    # Update configuration file with optimized parameters\n",
    "    if training_schedules:\n",
    "        # Create updated configuration\n",
    "        updated_config = current_config.copy()\n",
    "        if 'training_schedules' not in updated_config:\n",
    "            updated_config['training_schedules'] = {}\n",
    "        \n",
    "        updated_config['training_schedules'].update(training_schedules)\n",
    "        updated_config['optimization_metadata'] = {\n",
    "            \"last_optimization\": datetime.now().isoformat(),\n",
    "            \"optimized_models\": list(training_schedules.keys()),\n",
    "            \"optimization_version\": \"v1.0\"\n",
    "        }\n",
    "        \n",
    "        # Save updated configuration\n",
    "        backup_path = config_path.with_suffix(f'.backup_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n",
    "        with open(backup_path, 'w') as f:\n",
    "            json.dump(current_config, f, indent=2)\n",
    "        \n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(updated_config, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nConfiguration Updated:\")\n",
    "        print(f\"  Original config backed up to: {backup_path.name}\")\n",
    "        print(f\"  Updated config saved to: {config_path.name}\")\n",
    "        print(f\"  Training schedules generated for {len(training_schedules)} models\")\n",
    "        \n",
    "        logger.info(f\"Configuration updated with {len(training_schedules)} optimized training schedules\")\n",
    "    else:\n",
    "        print(\"No valid models found for schedule generation\")\n",
    "        logger.warning(\"No training schedules generated - no models passed validation\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to generate training schedules: {e}\")\n",
    "    print(f\"Error: Failed to generate training schedules - {e}\")\n",
    "\n",
    "print(f\"\\nOptimization Pipeline Complete\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Ready for production training with optimized parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
