{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b61d324",
   "metadata": {},
   "source": [
    "# Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4c07ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pre_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0xf949465ae9e0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at f948af0a2cb0, raw_cell=\"import sys\n",
      "import os\n",
      "import time\n",
      "import torch\n",
      "impo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khalil/DNN_tmp/llm/notebooks/02_model_training.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:582\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:779\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:290\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:170\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    168\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    169\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0xf949465ae9e0>> (for post_run_cell), with arguments args (<ExecutionResult object at f948af0a2fe0, execution_count=10 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at f948af0a2cb0, raw_cell=\"import sys\n",
      "import os\n",
      "import time\n",
      "import torch\n",
      "impo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khalil/DNN_tmp/llm/notebooks/02_model_training.ipynb#Y244sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:787\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:294\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:170\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    168\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    169\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.core.trainer import DialogTrainer\n",
    "from src.config.settings import get_model_config, get_test_config, get_development_config\n",
    "from src.data.loaders import get_dataset_manager\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0252f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pre_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0xf949465ae9e0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at f948af7332b0, raw_cell=\"# Setup WandB authentication\n",
      "from dotenv import lo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khalil/DNN_tmp/llm/notebooks/02_model_training.ipynb#Y245sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:582\u001b[0m, in \u001b[0;36m_WandbInit._pre_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:779\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:290\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:170\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    168\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    169\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ WandB connection established\n",
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0xf949465ae9e0>> (for post_run_cell), with arguments args (<ExecutionResult object at f948af733400, execution_count=11 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at f948af7332b0, raw_cell=\"# Setup WandB authentication\n",
      "from dotenv import lo..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khalil/DNN_tmp/llm/notebooks/02_model_training.ipynb#Y245sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:787\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:294\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:170\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    168\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    169\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DNN_tmp/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# Clean up any existing wandb runs\n",
    "try:\n",
    "    wandb.finish()\n",
    "    print(\"Cleaned up existing wandb run\")\n",
    "except:\n",
    "    print(\"No existing wandb run to clean up\")\n",
    "\n",
    "# Setup WandB authentication\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "wandb_api_key = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    print(\"✓ WandB connection established\")\n",
    "else:\n",
    "    print(\"⚠ No WandB key found - need to fix the .env file\")\n",
    "    print(\"Reminder: Add WANDB_API_KEY=your_actual_key to .env file\")\n",
    "    print(\"Training will continue without WandB logging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "195f0d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khalil/DNN_tmp/llm/notebooks/wandb/run-20250722_172243-tzcy6pu4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/tzcy6pu4' target=\"_blank\">model-comparison-20250722-1722</a></strong> to <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/tzcy6pu4' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/tzcy6pu4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Main WandB experiment tracking started\n",
      "Run name: model-comparison-20250722-1722\n",
      "Project: dialog-model-training\n"
     ]
    }
   ],
   "source": [
    "# Initialize main WandB run for model comparison experiment\n",
    "main_run = wandb.init(\n",
    "    project=\"dialog-model-training\",\n",
    "    name=f\"model-comparison-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n",
    "    tags=[\"comparison\", \"training\", \"notebook\"],\n",
    "    notes=\"Comparing multiple dialog model architectures: GPT-2, DialoGPT, and custom models\"\n",
    ")\n",
    "\n",
    "print(\"✓ Main WandB experiment tracking started\")\n",
    "print(f\"Run name: {main_run.name}\")\n",
    "print(f\"Project: {main_run.project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from local file: data/alpaca-gpt4.csv\n",
      "Training Configuration:\n",
      "- Epochs: 1\n",
      "- Batch size: 2\n",
      "- Max samples: 100\n",
      "- Learning rate: 5e-05\n",
      "\n",
      "Models to train and compare: ['custom-small']\n",
      "Dataset loaded: 52002 samples\n",
      "Training Configuration:\n",
      "- Epochs: 1\n",
      "- Batch size: 2\n",
      "- Max samples: 100\n",
      "- Learning rate: 5e-05\n",
      "\n",
      "Models to train and compare: ['custom-small']\n",
      "Dataset loaded: 52002 samples\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and configuration\n",
    "dataset_manager = get_dataset_manager()\n",
    "df = dataset_manager.load_dataset()\n",
    "training_config = get_development_config()\n",
    "\n",
    "# Models to compare\n",
    "models_to_train = [\n",
    "    #\"gpt2-small\",      # Pre-trained GPT-2\n",
    "    \"custom-small\",    # Custom model from scratch\n",
    "    #\"dialogpt-small\"   # Pre-trained DialoGPT\n",
    "]\n",
    "\n",
    "# Single consolidated output to avoid duplicates\n",
    "output = []\n",
    "output.append(\"Training Configuration:\")\n",
    "output.append(f\"- Epochs: {training_config.num_epochs}\")\n",
    "output.append(f\"- Batch size: {training_config.batch_size}\")\n",
    "output.append(f\"- Max samples: {training_config.max_samples}\")\n",
    "output.append(f\"- Learning rate: {training_config.learning_rate}\")\n",
    "output.append(f\"\\nModels to train and compare: {models_to_train}\")\n",
    "output.append(f\"Dataset loaded: {len(df)} samples\")\n",
    "\n",
    "print(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50488b",
   "metadata": {},
   "source": [
    "## Training Loop with WandB Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_logging(model_name, df, training_config, main_wandb_run):\n",
    "    \"\"\"Train a model with streamlined WandB logging\"\"\"\n",
    "    \n",
    "    # Get model config and initialize trainer with wandb run\n",
    "    model_config = get_model_config(model_name)\n",
    "    trainer = DialogTrainer(model_config=model_config, wandb_run=main_wandb_run)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Prepare dataset\n",
    "    train_dataset, eval_dataset = trainer.prepare_dataset(\n",
    "        df, \n",
    "        max_samples=training_config.max_samples\n",
    "    )\n",
    "    \n",
    "    # Start training with wandb logging built into trainer\n",
    "    start_time = datetime.now()\n",
    "    trainer.train(\n",
    "        train_dataset, \n",
    "        eval_dataset, \n",
    "        num_epochs=training_config.num_epochs,\n",
    "        batch_size=training_config.batch_size,\n",
    "        learning_rate=training_config.learning_rate\n",
    "    )\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    training_time = (end_time - start_time).total_seconds()\n",
    "    print(f\"Training completed in {training_time/60:.1f} minutes\")\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "# Store trained models for comparison\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing initial WandB run...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">model-comparison-20250722-1722</strong> at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/tzcy6pu4' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/tzcy6pu4</a><br> View project at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250722_172243-tzcy6pu4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for custom-small...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khalil/DNN_tmp/llm/notebooks/wandb/run-20250722_172246-14mlqcvi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual/runs/14mlqcvi' target=\"_blank\">training-custom-small-20250722-1722</a></strong> to <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual/runs/14mlqcvi' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual/runs/14mlqcvi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building custom model from scratch: custom-gpt-small\n",
      "Architecture: 8 layers, 512 dim, 8 heads\n",
      "Output directory: ./models/custom_small\n",
      "Custom GPT model initialized:\n",
      "  Parameters: 76,945,408\n",
      "  Layers: 8\n",
      "  Embedding dim: 512\n",
      "  Attention heads: 8\n",
      "Device: cpu\n",
      "Model parameters: 76,945,408\n",
      "\n",
      "==================================================\n",
      "Training custom-small\n",
      "==================================================\n",
      "Using 100 samples for training\n",
      "Training samples: 90\n",
      "Evaluation samples: 10\n",
      "Custom GPT model initialized:\n",
      "  Parameters: 76,945,408\n",
      "  Layers: 8\n",
      "  Embedding dim: 512\n",
      "  Attention heads: 8\n",
      "Device: cpu\n",
      "Model parameters: 76,945,408\n",
      "\n",
      "==================================================\n",
      "Training custom-small\n",
      "==================================================\n",
      "Using 100 samples for training\n",
      "Training samples: 90\n",
      "Evaluation samples: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e08de97b9e4f66881f79b04f0e2c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5a394cc3284c3ebefa58831e8a9ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khalil/DNN_tmp/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed! Model saved to ./models/custom_small\n",
      "Training completed in 0.8 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset_size</td><td>▁</td></tr><tr><td>eval_size</td><td>▁</td></tr><tr><td>model_parameters</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁▁</td></tr><tr><td>training_time_minutes</td><td>▁</td></tr><tr><td>training_time_seconds</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset_size</td><td>90</td></tr><tr><td>eval_size</td><td>10</td></tr><tr><td>model_parameters</td><td>76945408</td></tr><tr><td>total_flos</td><td>6872362598400.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>45</td></tr><tr><td>train_loss</td><td>10.15426</td></tr><tr><td>train_runtime</td><td>50.1872</td></tr><tr><td>train_samples_per_second</td><td>1.793</td></tr><tr><td>train_steps_per_second</td><td>0.897</td></tr><tr><td>training_time_minutes</td><td>0.84981</td></tr><tr><td>training_time_seconds</td><td>50.98875</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">training-custom-small-20250722-1722</strong> at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual/runs/14mlqcvi' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual/runs/14mlqcvi</a><br> View project at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training-individual</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250722_172246-14mlqcvi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY trained custom-small\n",
      "\n",
      "Training Summary:\n",
      "Successfully trained: ['custom-small']\n",
      "Total models trained: 1\n",
      "\n",
      "Initializing main WandB run for generation testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/khalil/DNN_tmp/llm/notebooks/wandb/run-20250722_172342-gpulq253</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/gpulq253' target=\"_blank\">generation-results-20250722-1723</a></strong> to <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/gpulq253' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/gpulq253</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train all models using the main wandb run\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\nStarting training for {model_name}...\")\n",
    "    try:\n",
    "        trainer = train_model_with_logging(model_name, df, training_config, main_run)\n",
    "        trained_models[model_name] = trainer\n",
    "        print(f\"SUCCESSFULLY trained {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED to train {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"Successfully trained: {list(trained_models.keys())}\")\n",
    "print(f\"Total models trained: {len(trained_models)}\")\n",
    "\n",
    "# Log training completion summary to main run\n",
    "main_run.log({\n",
    "    \"training/completed\": True,\n",
    "    \"training/models_successfully_trained\": len(trained_models),\n",
    "    \"training/completion_time\": datetime.now().timestamp(),\n",
    "    \"training/successful_models\": list(trained_models.keys())\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cef38",
   "metadata": {},
   "source": [
    "## Dialog Generation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d568af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Generation Comparison\n",
      "============================================================\n",
      "\n",
      "[1/5] Instruction: Explain what machine learning is in simple terms.\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: bill\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      " options the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      " task the\n",
      ". Store,bill such Quan\n",
      " the\n",
      "\n",
      "\n",
      " helmet\n",
      ",. the\n",
      ", a,\n",
      "\n",
      "xton.,\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      ".\n",
      ",,\n",
      " Quan\n",
      "============================================================\n",
      "\n",
      "[2/5] Instruction: How do I make a good cup of coffee?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: bill\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      " options the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      " task the\n",
      ". Store,bill such Quan\n",
      " the\n",
      "\n",
      "\n",
      " helmet\n",
      ",. the\n",
      ", a,\n",
      "\n",
      "xton.,\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      ".\n",
      ",,\n",
      " Quan\n",
      "============================================================\n",
      "\n",
      "[2/5] Instruction: How do I make a good cup of coffee?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: the.\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      "bill\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " reliable\n",
      " the Thirty thexton\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " options925\n",
      " final and\n",
      "\n",
      " the such the\n",
      "\n",
      "\n",
      " Stanford.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      ",\n",
      ",\n",
      "\n",
      "\n",
      " Columbia,.dm.\n",
      "\n",
      ",\n",
      " the horse and\n",
      " horse. legislative\n",
      "============================================================\n",
      "\n",
      "[3/5] Instruction: What are the benefits of exercise?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: the.\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      "bill\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " reliable\n",
      " the Thirty thexton\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " options925\n",
      " final and\n",
      "\n",
      " the such the\n",
      "\n",
      "\n",
      " Stanford.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      ",\n",
      ",\n",
      "\n",
      "\n",
      " Columbia,.dm.\n",
      "\n",
      ",\n",
      " the horse and\n",
      " horse. legislative\n",
      "============================================================\n",
      "\n",
      "[3/5] Instruction: What are the benefits of exercise?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: the.\n",
      "###\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      " theYesterday\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      " in,Yesterday. the\n",
      " the FILE\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      ". horse\n",
      ".. a.:. the\n",
      "\n",
      "arist.\n",
      "\n",
      "\n",
      "\n",
      " a\n",
      ",.,\n",
      ".\n",
      "\n",
      ".\n",
      "============================================================\n",
      "\n",
      "[4/5] Instruction: Tell me about the solar system.\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: the.\n",
      "###\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      " theYesterday\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      " in,Yesterday. the\n",
      " the FILE\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      ". horse\n",
      ".. a.:. the\n",
      "\n",
      "arist.\n",
      "\n",
      "\n",
      "\n",
      " a\n",
      ",.,\n",
      ".\n",
      "\n",
      ".\n",
      "============================================================\n",
      "\n",
      "[4/5] Instruction: Tell me about the solar system.\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: ..\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Streamer\n",
      "\n",
      ", integration\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",.\n",
      "\n",
      ",,\n",
      "\n",
      " theeq\n",
      " the,.\n",
      "\n",
      "\n",
      " reliable\n",
      " the\n",
      "dm\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      "925 Columbia\n",
      " the\n",
      ",\n",
      ".\n",
      "..\n",
      ":.,\n",
      ".\n",
      "============================================================\n",
      "\n",
      "[5/5] Instruction: How can I improve my communication skills?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: ..\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Streamer\n",
      "\n",
      ", integration\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",.\n",
      "\n",
      ",,\n",
      "\n",
      " theeq\n",
      " the,.\n",
      "\n",
      "\n",
      " reliable\n",
      " the\n",
      "dm\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      "925 Columbia\n",
      " the\n",
      ",\n",
      ".\n",
      "..\n",
      ":.,\n",
      ".\n",
      "============================================================\n",
      "\n",
      "[5/5] Instruction: How can I improve my communication skills?\n",
      "----------------------------------------\n",
      "\n",
      "custom-small: ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      " the incident\n",
      "\n",
      "\n",
      " maintaining\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      " is\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      " STD\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      " bite\n",
      "dm the,.\n",
      " the\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      " a\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      " such,\n",
      "\n",
      " tomatoes.\n",
      "xton,\n",
      "============================================================\n",
      "Generation testing completed!\n",
      "Generated 5 total responses\n",
      "\n",
      "custom-small: ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      " the incident\n",
      "\n",
      "\n",
      " maintaining\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      " the the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      " is\n",
      "\n",
      " the.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      "\n",
      " the\n",
      "\n",
      " STD\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      " bite\n",
      "dm the,.\n",
      " the\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      " a\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      " such,\n",
      "\n",
      " tomatoes.\n",
      "xton,\n",
      "============================================================\n",
      "Generation testing completed!\n",
      "Generated 5 total responses\n"
     ]
    }
   ],
   "source": [
    "# Test instructions for dialog generation\n",
    "test_instructions = [\n",
    "    \"Explain what machine learning is in simple terms.\",\n",
    "    \"How do I make a good cup of coffee?\",\n",
    "    \"What are the benefits of exercise?\",\n",
    "    \"Tell me about the solar system.\",\n",
    "    \"How can I improve my communication skills?\"\n",
    "]\n",
    "\n",
    "print(\"Dialog Generation Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create wandb table for generation results\n",
    "generation_table = wandb.Table(columns=[\n",
    "    \"Model\", \"Instruction\", \"Response\", \"Response_Length\", \n",
    "    \"Word_Count\", \"Generation_Time_Seconds\", \"Instruction_ID\"\n",
    "])\n",
    "\n",
    "# Store metrics for aggregation\n",
    "generation_metrics = {}\n",
    "\n",
    "for i, instruction in enumerate(test_instructions, 1):\n",
    "    print(f\"\\n[{i}/{len(test_instructions)}] Instruction: {instruction}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name, trainer in trained_models.items():\n",
    "        try:\n",
    "            start_time = datetime.now()\n",
    "            # Use wandb logging in generation\n",
    "            response = trainer.generate_response(instruction, max_length=100, log_to_wandb=True)\n",
    "            generation_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            print(f\"\\n{model_name}: {response}\")\n",
    "            \n",
    "            # Add to wandb table\n",
    "            generation_table.add_data(\n",
    "                model_name,\n",
    "                instruction[:100] + \"...\" if len(instruction) > 100 else instruction,\n",
    "                response[:200] + \"...\" if len(response) > 200 else response,\n",
    "                len(response),\n",
    "                len(response.split()),\n",
    "                round(generation_time, 3),\n",
    "                i\n",
    "            )\n",
    "            \n",
    "            # Track metrics per model for aggregation\n",
    "            if model_name not in generation_metrics:\n",
    "                generation_metrics[model_name] = {\n",
    "                    \"total_time\": 0,\n",
    "                    \"total_responses\": 0,\n",
    "                    \"total_length\": 0,\n",
    "                    \"total_words\": 0,\n",
    "                    \"successful_generations\": 0\n",
    "                }\n",
    "            \n",
    "            generation_metrics[model_name][\"total_time\"] += generation_time\n",
    "            generation_metrics[model_name][\"total_responses\"] += 1\n",
    "            generation_metrics[model_name][\"total_length\"] += len(response)\n",
    "            generation_metrics[model_name][\"total_words\"] += len(response.split())\n",
    "            generation_metrics[model_name][\"successful_generations\"] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n{model_name}: Error - {e}\")\n",
    "            # Log error to wandb\n",
    "            main_run.log({\n",
    "                f\"generation/error_{model_name}_instruction_{i}\": str(e)\n",
    "            })\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(f\"Generation testing completed!\")\n",
    "print(f\"Generated {sum(metrics['successful_generations'] for metrics in generation_metrics.values())} total responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446b1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging generation metrics to WandB...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>custom-small_avg_generation_time</td><td>▁</td></tr><tr><td>custom-small_avg_response_length</td><td>▁</td></tr><tr><td>custom-small_avg_response_words</td><td>▁</td></tr><tr><td>custom-small_responses_generated</td><td>▁</td></tr><tr><td>custom-small_total_generation_time</td><td>▁</td></tr><tr><td>models_successfully_trained</td><td>▁</td></tr><tr><td>models_trained</td><td>▁</td></tr><tr><td>total_generations</td><td>▁</td></tr><tr><td>total_test_instructions</td><td>▁</td></tr><tr><td>training_completion_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>custom-small_avg_generation_time</td><td>7.95595</td></tr><tr><td>custom-small_avg_response_length</td><td>165.2</td></tr><tr><td>custom-small_avg_response_words</td><td>26.2</td></tr><tr><td>custom-small_responses_generated</td><td>5</td></tr><tr><td>custom-small_total_generation_time</td><td>39.77974</td></tr><tr><td>experiment_status</td><td>completed</td></tr><tr><td>generation_test_completed</td><td>True</td></tr><tr><td>models_successfully_trained</td><td>1</td></tr><tr><td>models_trained</td><td>1</td></tr><tr><td>total_generations</td><td>5</td></tr><tr><td>total_test_instructions</td><td>5</td></tr><tr><td>training_completed</td><td>True</td></tr><tr><td>training_completion_time</td><td>1753197824.19334</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generation-results-20250722-1723</strong> at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/gpulq253' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training/runs/gpulq253</a><br> View project at: <a href='https://wandb.ai/tenchishishou-epfl/dialog-model-training' target=\"_blank\">https://wandb.ai/tenchishishou-epfl/dialog-model-training</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250722_172342-gpulq253/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment completed successfully.\n",
      "Trained 1 models and completed generation testing.\n"
     ]
    }
   ],
   "source": [
    "# Log the comprehensive generation comparison table\n",
    "main_run.log({\"generation_comparison_detailed\": generation_table})\n",
    "\n",
    "# Log aggregated metrics for each model\n",
    "print(\"Logging final generation metrics to WandB...\")\n",
    "\n",
    "for model_name, metrics in generation_metrics.items():\n",
    "    if metrics[\"total_responses\"] > 0:  # Avoid division by zero\n",
    "        avg_metrics = {\n",
    "            f\"generation_summary/{model_name}_avg_time\": metrics[\"total_time\"] / metrics[\"total_responses\"],\n",
    "            f\"generation_summary/{model_name}_avg_length\": metrics[\"total_length\"] / metrics[\"total_responses\"],\n",
    "            f\"generation_summary/{model_name}_avg_words\": metrics[\"total_words\"] / metrics[\"total_responses\"],\n",
    "            f\"generation_summary/{model_name}_total_time\": metrics[\"total_time\"],\n",
    "            f\"generation_summary/{model_name}_success_rate\": metrics[\"successful_generations\"] / len(test_instructions),\n",
    "            f\"generation_summary/{model_name}_responses_generated\": metrics[\"successful_generations\"]\n",
    "        }\n",
    "        main_run.log(avg_metrics)\n",
    "\n",
    "# Create a model comparison summary table\n",
    "comparison_summary = wandb.Table(columns=[\n",
    "    \"Model\", \"Avg_Generation_Time\", \"Avg_Response_Length\", \n",
    "    \"Avg_Word_Count\", \"Success_Rate\", \"Total_Responses\"\n",
    "])\n",
    "\n",
    "for model_name, metrics in generation_metrics.items():\n",
    "    if metrics[\"total_responses\"] > 0:\n",
    "        comparison_summary.add_data(\n",
    "            model_name,\n",
    "            round(metrics[\"total_time\"] / metrics[\"total_responses\"], 3),\n",
    "            round(metrics[\"total_length\"] / metrics[\"total_responses\"], 1),\n",
    "            round(metrics[\"total_words\"] / metrics[\"total_responses\"], 1),\n",
    "            round(metrics[\"successful_generations\"] / len(test_instructions), 2),\n",
    "            metrics[\"successful_generations\"]\n",
    "        )\n",
    "\n",
    "main_run.log({\"model_comparison_summary\": comparison_summary})\n",
    "\n",
    "# Log experiment completion\n",
    "final_summary = {\n",
    "    \"experiment/status\": \"completed\",\n",
    "    \"experiment/models_trained\": len(trained_models),\n",
    "    \"experiment/test_instructions\": len(test_instructions),\n",
    "    \"experiment/total_generations\": sum(metrics[\"successful_generations\"] for metrics in generation_metrics.values()),\n",
    "    \"experiment/completion_timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "main_run.log(final_summary)\n",
    "\n",
    "# Close WandB run\n",
    "main_run.finish()\n",
    "\n",
    "print(\"✓ Experiment completed successfully\")\n",
    "print(f\"✓ Trained {len(trained_models)} models\")\n",
    "print(f\"✓ Generated {sum(metrics['successful_generations'] for metrics in generation_metrics.values())} responses\")\n",
    "print(\"✓ All results logged to WandB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
