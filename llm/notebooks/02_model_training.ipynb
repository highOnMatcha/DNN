{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b61d324",
   "metadata": {},
   "source": [
    "# Model Training and Comparison\n",
    "\n",
    "This notebook implements and compares different dialog model architectures:\n",
    "- Fine-tuned pre-trained models (GPT-2, DialoGPT)\n",
    "- Custom transformer models built from scratch\n",
    "- Training with WandB logging and experiment tracking\n",
    "\n",
    "## Objectives:\n",
    "- Train multiple model variants for comparison\n",
    "- Track experiments with WandB\n",
    "- Evaluate model performance on dialog tasks\n",
    "- Generate and test dialog responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../')\n",
    "from src.core.trainer import DialogTrainer\n",
    "from src.config.settings import get_model_config, get_test_config, get_development_config\n",
    "from src.data.loaders import get_dataset_manager\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_manager = get_dataset_manager()\n",
    "df = dataset_manager.load_dataset()\n",
    "\n",
    "# Use development config for notebook (faster training)\n",
    "training_config = get_development_config()\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"- Epochs: {training_config.num_epochs}\")\n",
    "print(f\"- Batch size: {training_config.batch_size}\")\n",
    "print(f\"- Max samples: {training_config.max_samples}\")\n",
    "print(f\"- Learning rate: {training_config.learning_rate}\")\n",
    "\n",
    "# Models to compare\n",
    "models_to_train = [\n",
    "    \"gpt2-small\",      # Pre-trained GPT-2\n",
    "    \"custom-small\",    # Custom model from scratch\n",
    "    \"dialogpt-small\"   # Pre-trained DialoGPT\n",
    "]\n",
    "\n",
    "print(f\"\\nModels to train and compare: {models_to_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50488b",
   "metadata": {},
   "source": [
    "## Training Loop with WandB Tracking\n",
    "\n",
    "Train each model variant and log metrics to WandB for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_logging(model_name, df, training_config):\n",
    "    \"\"\"Train a model with WandB logging\"\"\"\n",
    "    \n",
    "    # Initialize WandB run for this model\n",
    "    run = wandb.init(\n",
    "        project=\"dialog-model-training\",\n",
    "        name=f\"training-{model_name}-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n",
    "        tags=[\"training\", model_name],\n",
    "        config={\n",
    "            \"model\": model_name,\n",
    "            \"epochs\": training_config.num_epochs,\n",
    "            \"batch_size\": training_config.batch_size,\n",
    "            \"learning_rate\": training_config.learning_rate,\n",
    "            \"max_samples\": training_config.max_samples\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Get model config and initialize trainer\n",
    "        model_config = get_model_config(model_name)\n",
    "        trainer = DialogTrainer(model_config=model_config)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {model_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Prepare dataset\n",
    "        train_dataset, eval_dataset = trainer.prepare_dataset(\n",
    "            df, \n",
    "            max_samples=training_config.max_samples\n",
    "        )\n",
    "        \n",
    "        # Start training\n",
    "        start_time = datetime.now()\n",
    "        trainer.train(\n",
    "            train_dataset, \n",
    "            eval_dataset, \n",
    "            num_epochs=training_config.num_epochs,\n",
    "            batch_size=training_config.batch_size,\n",
    "            learning_rate=training_config.learning_rate\n",
    "        )\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # Log final metrics\n",
    "        wandb.log({\n",
    "            \"training_time_seconds\": training_time,\n",
    "            \"training_time_minutes\": training_time / 60,\n",
    "            \"model_parameters\": sum(p.numel() for p in trainer.model.parameters()),\n",
    "            \"dataset_size\": len(train_dataset),\n",
    "            \"eval_size\": len(eval_dataset)\n",
    "        })\n",
    "        \n",
    "        print(f\"Training completed in {training_time/60:.1f} minutes\")\n",
    "        return trainer\n",
    "        \n",
    "    finally:\n",
    "        wandb.finish()\n",
    "\n",
    "# Store trained models for comparison\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "for model_name in models_to_train:\n",
    "    print(f\"\\nStarting training for {model_name}...\")\n",
    "    try:\n",
    "        trainer = train_model_with_logging(model_name, df, training_config)\n",
    "        trained_models[model_name] = trainer\n",
    "        print(f\"✓ Successfully trained {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to train {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"Successfully trained: {list(trained_models.keys())}\")\n",
    "print(f\"Total models trained: {len(trained_models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cef38",
   "metadata": {},
   "source": [
    "## Dialog Generation Testing\n",
    "\n",
    "Test the trained models by generating responses to sample instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d568af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test instructions for dialog generation\n",
    "test_instructions = [\n",
    "    \"Explain what machine learning is in simple terms.\",\n",
    "    \"How do I make a good cup of coffee?\",\n",
    "    \"What are the benefits of exercise?\",\n",
    "    \"Tell me about the solar system.\",\n",
    "    \"How can I improve my communication skills?\"\n",
    "]\n",
    "\n",
    "print(\"Dialog Generation Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for instruction in test_instructions:\n",
    "    print(f\"\\nInstruction: {instruction}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_name, trainer in trained_models.items():\n",
    "        try:\n",
    "            response = trainer.generate_response(instruction, max_length=100)\n",
    "            print(f\"\\n{model_name}: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n{model_name}: Error - {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646d887",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Test your own custom instructions with the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_instruction(instruction, model_name=None):\n",
    "    \"\"\"Test a custom instruction with trained models\"\"\"\n",
    "    if model_name and model_name in trained_models:\n",
    "        # Test specific model\n",
    "        trainer = trained_models[model_name]\n",
    "        response = trainer.generate_response(instruction, max_length=150)\n",
    "        print(f\"{model_name}: {response}\")\n",
    "    else:\n",
    "        # Test all models\n",
    "        print(f\"Testing: {instruction}\")\n",
    "        print(\"-\" * 50)\n",
    "        for name, trainer in trained_models.items():\n",
    "            try:\n",
    "                response = trainer.generate_response(instruction, max_length=150)\n",
    "                print(f\"\\n{name}: {response}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n{name}: Error - {e}\")\n",
    "\n",
    "# Example usage - modify the instruction below to test your own\n",
    "custom_instruction = \"What is the most important skill for a data scientist?\"\n",
    "test_custom_instruction(custom_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cb8e3",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### Training Results:\n",
    "- Successfully trained multiple dialog model variants\n",
    "- Compared pre-trained vs custom architectures\n",
    "- All experiments tracked in WandB with metrics and visualizations\n",
    "\n",
    "### Model Comparison Insights:\n",
    "1. **Pre-trained models** (GPT-2, DialoGPT) benefit from existing language knowledge\n",
    "2. **Custom models** offer more control but require more training data\n",
    "3. **Training time** varies significantly between architectures\n",
    "\n",
    "### Next Steps:\n",
    "- Evaluate models on held-out test set\n",
    "- Implement additional metrics (BLEU, perplexity)\n",
    "- Fine-tune hyperparameters based on results\n",
    "- Deploy best-performing model for production testing\n",
    "\n",
    "Check your WandB dashboard for detailed training metrics and comparisons!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
